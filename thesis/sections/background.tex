% ============================================================================
% Chapter 2: Background
% ============================================================================

\chapter{Background}
\label{ch:background}

This chapter presents the theoretical and technical foundations underpinning this thesis. It introduces the Model Context Protocol (MCP) as a model-facing standard for protocol-driven robotics, situates it with respect to the Robot Operating System 2 (ROS~2), and reviews core concepts in relational reasoning and forward dynamics that support evidence-based agentic planning and swappable intelligence.

\section{The Model Context Protocol (MCP)}

The Model Context Protocol (MCP) is an emerging open standard for mediating interaction between AI models and external tools, services, and data resources. By defining a unified, bi-directional communication interface---typically instantiated via JSON-RPC 2.0\cite{wang_towards_2025}---MCP enables interoperability across heterogeneous ecosystems and decouples model-centric reasoning from system-specific implementation details \cite{lee_robot_2025}. 

MCP adopts a three-tier architecture comprising a \emph{Host} (e.g., an LLM-based application), a \emph{Client} (the transport layer), and a \emph{Server} (the gateway exposing tools and resources). Within this architecture, primitives such as \emph{Tools}, \emph{Resources}, and \emph{Prompts} provide an abstraction layer over concrete capabilities, allowing AI agents to invoke functionality without assuming a particular runtime or hardware configuration. Recent work positions MCP as a general-purpose ``tool bus'' for robotic cognition, in which agentic planners discover and invoke robot capabilities dynamically via semantic URIs \cite{lee_robot_2025}. 

In the context of protocol-driven robotics, MCP serves as the model-adjacent interface that exposes robot affordances in a standardized, auditable form. This thesis leverages MCP to support swappable intelligence: different foundation models can be attached to the same physical system without modifying the underlying control stack, as long as they comply with the shared protocol.\cite{wang_towards_2025}

\section{Robot Operating System 2 (ROS~2)}

The Robot Operating System 2 (ROS~2) is the de facto middleware standard for contemporary robotic systems, providing real-time, distributed communication over a Data Distribution Service (DDS) backbone \cite{gambo_systematic_2025}. ROS~2 standardizes intra-robot messaging through \emph{Topics} (publish--subscribe), \emph{Services} (request--response), and \emph{Actions} (long-running, goal-oriented interactions), thereby offering a unified abstraction over heterogeneous sensors, actuators, and controllers.

While ROS~2 is highly effective as a hardware-adjacent execution layer, it does not natively provide high-level, model-facing interfaces suitable for non-deterministic AI  \cite{pistilli_graph_2023, lee_robot_2025}. As a consequence, integration with external planners or large language models typically proceeds via bespoke, platform-specific bridges that are brittle, difficult to reuse, and challenging to audit from a safety perspective \cite{wirkus_online_2020}. 

In this work, ROS~2 is treated as the low-level execution substrate responsible for real-time control, state dissemination, and device management. The proposed MCP--ROS~2 bridge then functions as a protocol-level adaptor: it exposes ROS~2 capabilities as MCP Tools and Resources, enabling agentic planning to interact with the robot through a standardized interface while preserving ROS~2's real-time guarantees. This separation of concerns is central to achieving hardware-agnostic, swappable intelligence.

\section{Relational Reasoning with Graph Neural Networks}

Graph Neural Networks (GNNs) are a class of neural architectures designed to operate on graph-structured data, providing a natural relational inductive bias and permutation invariance over entities and their interactions \cite{huang_planning_2022}. For robotic manipulation, such relational structure is critical: the physical relationship between, for example, a gripper and an object is often more informative for planning than their absolute poses in a global reference frame \cite{rabino_modern_2024, velickovic_everything_2023, lin_efficient_2021}. 

GNNs implement relational reasoning via iterative message passing on a graph whose nodes represent entities (e.g., joints, links, or objects) and whose edges encode spatial or semantic relationships. A generic message-passing update can be written as
\begin{equation}
h^{(l+1)}_v = \phi \left( h^{(l)}_v, \bigoplus_{u \in N(v)} \psi\big(h^{(l)}_v, h^{(l)}_u, e_{uv}\big) \right),
\end{equation}
where $h^{(l)}_v$ is the representation of node $v$ at layer $l$, $N(v)$ is the neighborhood of $v$, $e_{uv}$ encodes edge features, $\psi$ is the message function, $\phi$ is the update function, and $\bigoplus$ is a permutation-invariant aggregation operator (e.g., sum, mean, or max). 

Within protocol-driven robotics, this thesis employs a relational GNN to transform high-throughput kinematic streams into structured spatial predicates that are consumable by LLM-based planners\cite{velickovic_everything_2023, lin_efficient_2021}. By grounding agentic planning in relational state representations derived from raw sensor data, the system can reason about contact, reachability, occlusion, and other geometric constraints that are essential for safe and effective physical interaction \cite{lin_efficient_2021, miao_semantic_2023}.

\section{Forward Dynamics and Physical Verification}

Safe embodied deployment of non-deterministic agents requires mechanisms to predict and evaluate the physical consequences of candidate action sequences prior to execution. Forward dynamics models and context-aware controllers play a key role in this process by forecasting future world states under proposed control inputs and identifying trajectories that violate kinematic, dynamic, or safety constraints \cite{roth_learned_2025, schneider_semantic_2025}.

This thesis integrates a learned Forward Dynamics Model into the MCP-based middleware as a protocol-level safety primitive. Given the current relational state and a sequence of proposed tool invocations, the model predicts future system configurations and flags trajectories that are physically implausible or unsafe. In effect, this component operates as a ``physicality filter'' within the protocol layer: it intercepts and vetoes agent-generated commands that would violate joint limits, self-collision constraints, or workspace safety regions \cite{lee_robot_2025}. This design aligns predictive simulation with protocol-level logging, providing both pre-execution verification and an interpretable audit trail of safety decisions.

\section{Related Work}

A growing body of work explores the integration of large foundation models with robotic systems. Approaches such as \textit{SayCan} and \textit{RT-2} demonstrate that LLMs and vision-language models can be grounded in robot affordances to produce semantically meaningful, long-horizon plans in real environments\cite{wang_towards_2025}. However, these systems are typically tightly coupled to specific hardware platforms, task domains, or proprietary APIs, limiting their portability and making systematic safety auditing more difficult.

In parallel, emerging protocol proposals such as the \textit{Robot Context Protocol} (RCP) highlight a shift toward runtime-agnostic, middleware-independent abstractions for multi-tenant robotic control \cite{lee_robot_2025}. These efforts aim to formalize the interface between cognitive agents and physical systems, but often do not yet incorporate explicit structures for relational reasoning or forward dynamics-based verification.

Complementary strands of research investigate semantic belief graphs, knowledge-graph-based task planning, and scene graph representations as foundations for long-term, memory-aware manipulation \cite{ginting_safe_2023, miao_long-term_2023}. These works underscore the importance of structured, graph-based state representations for robust plan generation and adaptation over extended horizons \cite{lin_efficient_2021, chen_overview_2023}.

This thesis builds directly on these foundations by (i) embedding a reasoning-capable relational GNN layer within a standardized, model-facing protocol framework, and (ii) coupling that framework to a learned forward dynamics component that provides protocol-level physicality checks. Together, these elements advance the goal of protocol-driven robotics by enabling swappable intelligence, structured relational state, and predictive safety guardrails within a single, unified middleware architecture.

\begin{table}[htbp]
\centering
\caption{Comparative Analysis of Embodied AI Integration Frameworks}
\label{tab:related-work-comparison}
\resizebox{\textwidth}{!}{% % This line forces the table to fit within the page width
\begin{tabular}{lccccr}
\toprule
\textbf{System} & \textbf{Protocol} & \textbf{Safety Layer} & \textbf{Swappability} & \textbf{Abstraction} & \textbf{Reasoning} \\
\midrule
SayCan \cite{saycan2022} & Proprietary & Affordance & Low & Task-Specific & Language \\
RT-2 \cite{rt22023} & None & Probabilistic & None & Monolithic VLA & Multimodal \\
RCP (Draft) \cite{lee_robot_2025} & RCP & Static Rules & Medium & Middleware & Variable \\
Modular ROS 2 & DDS/C++ & Hand-coded & Low & Hardware-Centric & Deterministic \\
\midrule
\textbf{AI2MCP (Ours)} & \textbf{MCP (Std.)} & \textbf{Sim-Verification} & \textbf{High (Hot-swap)} & \textbf{Tool-Centric} & \textbf{Kinematic GNN} \\
\bottomrule
\end{tabular}}
\end{table}